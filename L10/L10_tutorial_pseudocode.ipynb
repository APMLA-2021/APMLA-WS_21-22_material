{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poisson Matrix Factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disclaimer: these are non-sparse implementations.They can be optimized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.special as sp\n",
    "from scipy.stats import gamma, poisson\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import matplotlib\n",
    "\n",
    "import functions as fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prng = np.random.RandomState(10)  # container for the Mersenne Twister pseudo-random number generator\n",
    "cmap = matplotlib.cm.get_cmap('tab20')  # colormap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset\n",
    "graph = nx.read_gml('football/football_net.gml')\n",
    "# keep largest connected component\n",
    "Gcc = sorted(nx.connected_components(graph), key=len, reverse=True)\n",
    "graph = graph.subgraph(Gcc[0])\n",
    "\n",
    "print('nodes N =',graph.number_of_nodes(),'\\nedges E =',graph.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset covariates to create ground truth\n",
    "df = pd.read_csv('football/football_cov.csv')\n",
    "ground_lab = ['Atlantic Coast','Big East','Big Ten','Big Twelve','Conference USA','Big West','Mid-American',\n",
    "              'Mountain West','Pacific Ten','Southeastern','Western Athletic','NotreDame','Navy','Connecticut',\n",
    "              'CentralFlorida','Middle Tennessee State','LouisianaTech','LouisianaMonroe','LouisianaLafayette']\n",
    "ground_truth = {}\n",
    "for i,j in enumerate(ground_lab):\n",
    "    ground_truth[i] = list(df[df.conference==j].index)\n",
    "K = len(ground_truth)\n",
    "\n",
    "print('communities K =', K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)\n",
    "# the ground_truth is given by the conference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# defrozen graph and make directed\n",
    "graph = nx.DiGraph(graph)\n",
    "print('nodes N =',graph.number_of_nodes(),'\\nedges E =',graph.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete nodes belonging to communities having len=1\n",
    "del_idx = []\n",
    "for i in np.arange(11,19):\n",
    "    for v in ground_truth[i]:\n",
    "        n = df.iloc[v]['names']\n",
    "        del_idx.append(v)\n",
    "        graph.remove_node(n)\n",
    "df.drop(del_idx, inplace=True)\n",
    "df = df.reset_index()\n",
    "A = nx.to_numpy_array(graph)  # save adjacency matrix\n",
    "print('nodes N =', graph.number_of_nodes(),'\\nedges E =', graph.number_of_edges())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete communities having len=1\n",
    "ground_lab = ['Atlantic Coast','Big East','Big Ten','Big Twelve','Conference USA','Big West','Mid-American',\n",
    "              'Mountain West','Pacific Ten','Southeastern','Western Athletic']\n",
    "ground_truth = {}\n",
    "for i,j in enumerate(ground_lab):\n",
    "    ground_truth[i] = list(df[df.conference==j].index)\n",
    "K = len(ground_truth)\n",
    "\n",
    "print('communities K =', K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of ground truth network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# communities per node\n",
    "com = {}\n",
    "for k in ground_truth:\n",
    "    for v in ground_truth[k]:\n",
    "        com[v] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_size = [graph.degree[i]*17 for i in list(graph.nodes())]\n",
    "position = nx.spring_layout(graph,iterations=200,seed=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "fun.plot_net_hard(graph, position, node_size, com, plt, cmap)\n",
    "plt.title('Ground Truth Partition')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Inference with EM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (a) Complete the functions of the class PMF_EM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PMF_EM(object):\n",
    "    \n",
    "    def __init__(self, A, K=3):\n",
    "        self.A = A                 # data\n",
    "        self.K = K                 # number of communities\n",
    "        self.N = self.A.shape[0]   # number of nodes\n",
    "\n",
    "    def _init(self, prng):\n",
    "        # random initialization \n",
    "        self.u = # YOUR CODE HERE\n",
    "        self.v = # YOUR CODE HERE\n",
    "        self.C = # YOUR CODE HERE\n",
    "        \n",
    "    def fit(self, prng, N_real=15, max_iter=100, tol=0.1, decision=2):\n",
    "        maxL = - 1e12  # initialization of the maximum likelihood\n",
    "\n",
    "        for r in range(N_real):\n",
    "            # random initialization\n",
    "            self._init(prng)\n",
    "            \n",
    "            # convergence local variables\n",
    "            coincide, it = 0, 0\n",
    "            convergence = False\n",
    "\n",
    "            loglik_values = []  # keep track of the values of the loglik to plot\n",
    "            loglik = - 1e12  # initialization of the loglik\n",
    "\n",
    "            while not convergence and it < max_iter:\n",
    "                self._em()\n",
    "                it, loglik, coincide, convergence = self.check_for_convergence(it, loglik, coincide, convergence, tolerance=tol, decision=decision)\n",
    "                loglik_values.append(loglik)\n",
    "            print(f'Nreal = {r} - Loglikelihood = {fun.fl(loglik)} - Best Loglikelihood = {fun.fl(maxL)} - iterations = {it} - ')\n",
    "    \n",
    "            if maxL < loglik:\n",
    "                u_f,v_f,C_f = self.update_optimal_parameters()\n",
    "                maxL = loglik\n",
    "                final_it = it\n",
    "                best_loglik_values = list(loglik_values)\n",
    "        \n",
    "        return u_f, v_f, C_f, best_loglik_values\n",
    "\n",
    "    def _em(self):\n",
    "        # E-step\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        # M-step\n",
    "        # YOUR CODE HERE\n",
    "\n",
    "    def update_q(self):\n",
    "        # YOUR CODE HERE\n",
    "    \n",
    "    def update_u(self, q):\n",
    "        # YOUR CODE HERE\n",
    "\n",
    "    def update_v(self, q):\n",
    "        # YOUR CODE HERE\n",
    "\n",
    "    def update_C(self, q):\n",
    "        # YOUR CODE HERE\n",
    "    \n",
    "    def check_for_convergence(self, it, loglik, coincide, convergence, tolerance=0.1, decision=2):\n",
    "        if it % 10 == 0:\n",
    "            old_L = loglik\n",
    "            loglik = self.Likelihood(EPS = 1e-12)\n",
    "            if abs(loglik - old_L) < tolerance:\n",
    "                coincide += 1\n",
    "            else:\n",
    "                coincide = 0\n",
    "        if coincide > decision:\n",
    "            convergence = True\n",
    "        it += 1\n",
    "        return it, loglik, coincide, convergence\n",
    "\n",
    "    def Likelihood(self, EPS = 1e-12):\n",
    "        # YOUR CODE HERE\n",
    "\n",
    "    def update_optimal_parameters(self):\n",
    "        u_f = np.copy(self.u)\n",
    "        v_f = np.copy(self.v)\n",
    "        C_f = np.copy(self.C)\n",
    "        return u_f,v_f,C_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pmf_em = PMF_EM(A, K=K)\n",
    "u_em, v_em, C_em, best_loglik_values = pmf_em.fit(prng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (b) Plot the log-likelihood values  [check the script functions.py]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (c) Plot the results: ground truth vs estimated overlapping partition vs estimated hard partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_norm_em = fun.normalize_nonzero_membership(u_em)\n",
    "v_norm_em = fun.normalize_nonzero_membership(v_em)\n",
    "\n",
    "q_em = np.argmax(u_norm_em, axis=1)  # extract hard communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(24,8))\n",
    "plt.subplot(1,3,1)\n",
    "# YOUR CODE HERE\n",
    "plt.title('Ground Truth Partition')\n",
    "plt.subplot(1,3,2)\n",
    "# YOUR CODE HERE\n",
    "plt.title('Estimated via EM (soft)')\n",
    "plt.subplot(1,3,3)\n",
    "# YOUR CODE HERE\n",
    "plt.title('Estimated via EM (hard)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Inference with VI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (a) Complete the functions of the class PMF_VI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PMF_VI(object):\n",
    "    \n",
    "    def __init__(self, A, K=3):\n",
    "        self.A = A                 # data\n",
    "        self.K = K                 # number of communities\n",
    "        self.N = self.A.shape[0]   # number of nodes\n",
    "\n",
    "    def _init(self, prng):\n",
    "        # priors\n",
    "        self.a = 1\n",
    "        self.b = 1\n",
    "        self.c = 1\n",
    "        self.d = 1\n",
    "        \n",
    "        # random initialization\n",
    "        self.alpha_shp = # YOUR CODE HERE\n",
    "        self.alpha_rte = # YOUR CODE HERE\n",
    "        self.beta_shp = # YOUR CODE HERE\n",
    "        self.beta_rte = # YOUR CODE HERE\n",
    "\n",
    "    def fit(self, prng, N_real=15, max_iter=100, tol=0.1, decision=2):\n",
    "        maxElbo = - 1e12  # initialization of the maximum elbo\n",
    "\n",
    "        for r in range(N_real):\n",
    "            # random initialization\n",
    "            self._init(prng)\n",
    "\n",
    "            # convergence local variables\n",
    "            coincide, it = 0, 0\n",
    "            convergence = False\n",
    "\n",
    "            elbo_values = []  # keep track of the values of the elbo to plot\n",
    "            elbo = - 1e12  # initialization of the loglik\n",
    "\n",
    "            while not convergence and it < max_iter:\n",
    "                self._cavi()\n",
    "                \n",
    "                Eu, Elogu = compute_expectations(self.alpha_shp, self.alpha_rte)\n",
    "                Ev, Elogv = compute_expectations(self.beta_shp, self.beta_rte)\n",
    "\n",
    "                it, elbo, coincide, convergence = self.check_for_convergence_cavi(Eu, Elogu, Ev, Elogv, it, elbo, coincide,   \n",
    "                                                                          convergence, tolerance=tol, decision=decision)\n",
    "                elbo_values.append(elbo)\n",
    "            print(f'Nreal = {r} - ELBO = {fun.fl(elbo)} - Best ELBO = {fun.fl(maxElbo)} - iterations = {it} - ')\n",
    "\n",
    "            if maxElbo < elbo:\n",
    "                alpha_shp_f,alpha_rte_f,beta_shp_f,beta_rte_f = self.update_optimal_parameters()\n",
    "                maxElbo = elbo\n",
    "                final_it = it\n",
    "                best_elbo_values = list(elbo_values)\n",
    "        \n",
    "        return alpha_shp_f, alpha_rte_f, beta_shp_f, beta_rte_f, best_elbo_values\n",
    "\n",
    "    def _cavi(self):\n",
    "        # YOUR CODE HERE\n",
    "\n",
    "    def update_phi(self):\n",
    "        # YOUR CODE HERE\n",
    "    \n",
    "    def update_alphas(self, phi_ij):\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "    def update_betas(self, phi_ij):\n",
    "        # YOUR CODE HERE\n",
    "   \n",
    "    def check_for_convergence_cavi(self, Eu, Elogu, Ev, Elogv, it, elbo, coincide, convergence, tolerance=0.1,decision=2):\n",
    "        if it % 10 == 0:\n",
    "            old_elbo = elbo\n",
    "            elbo = self.Elbo(Eu, Elogu, Ev, Elogv)\n",
    "            if abs(elbo - old_elbo) < tolerance:\n",
    "                coincide += 1\n",
    "            else:\n",
    "                coincide = 0\n",
    "        if coincide > decision:\n",
    "            convergence = True\n",
    "        it += 1\n",
    "        return it, elbo, coincide, convergence\n",
    "\n",
    "    def Elbo(self, Eu, Elogu, Ev, Elogv):\n",
    "        # YOUR CODE HERE\n",
    "\n",
    "    def update_optimal_parameters(self):\n",
    "        alpha_shp = np.copy(self.alpha_shp)\n",
    "        alpha_rte = np.copy(self.alpha_rte)\n",
    "        beta_shp = np.copy(self.beta_shp)\n",
    "        beta_rte = np.copy(self.beta_rte)\n",
    "        return alpha_shp,alpha_rte,beta_shp,beta_rte\n",
    "    \n",
    "def compute_expectations(alpha, beta):\n",
    "    '''\n",
    "    Given x ~ Gam(alpha, beta), compute E[x] and E[log x]\n",
    "    '''    \n",
    "    return (alpha / beta , sp.psi(alpha) - np.log(beta))\n",
    "\n",
    "def gamma_elbo_term(pa, pb, qa, qb):\n",
    "        # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pmf_vi = PMF_VI(A, K=K)\n",
    "alpha_shp_vi, alpha_rte_vi, beta_shp_vi, beta_rte_vi, best_elbo_values = pmf_vi.fit(prng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Eu_vi, Elogu_vi = compute_expectations(alpha_shp_vi,alpha_rte_vi)\n",
    "Ev_vi, Elogv_vi = compute_expectations(beta_shp_vi,beta_rte_vi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (b) Plot the elbo values  [check the script functions.py]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (c) Plot the results: ground truth vs estimated overlapping partition vs estimated hard partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_norm_vi = fun.normalize_nonzero_membership(Eu_vi)\n",
    "v_norm_vi = fun.normalize_nonzero_membership(Ev_vi)\n",
    "\n",
    "q_vi = np.argmax(u_norm_vi, axis=1)  # extract hard communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(24,8))\n",
    "plt.subplot(1,3,1)\n",
    "# YOUR CODE HERE\n",
    "plt.title('Ground Truth Partition')\n",
    "plt.subplot(1,3,2)\n",
    "# YOUR CODE HERE\n",
    "plt.title('Estimated via EM (soft)')\n",
    "plt.subplot(1,3,3)\n",
    "# YOUR CODE HERE\n",
    "plt.title('Estimated via EM (hard)')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
