{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial 3: Bayesian Mixture Models and Gibbs sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Categorical Mixture Model (CMM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.special\n",
    "\n",
    "import math\n",
    "\n",
    "import gensim\n",
    "from wordcloud import WordCloud, STOPWORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load and pre-process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('tweets_cleaned.csv')\n",
    "df.drop_duplicates(subset=\"tweet\", inplace=True)  # drop duplicates tweets\n",
    "df['tokens'] = df['tokens'].apply(literal_eval)  # transform the string into a list of tokens\n",
    "X_tokens = list(df['tokens'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-778824ee1dc6c0d1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print('Columns: {}\\n'.format(' | '.join(df.columns.values)))\n",
    "\n",
    "print('Tweet:\\n{}'.format(df.loc[1, 'tweet']))\n",
    "print('Tweet cleaned:\\n{}'.format(df.loc[1, 'tweets_clean']))\n",
    "print('Tweet tokens:\\n{}'.format(X_tokens[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = 120  # hyperparameter: number of different words to keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(X_tokens)\n",
    "print(dictionary)\n",
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=I)\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create Bag of Words (BoW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_bow = list()\n",
    "keep_tweet = list()\n",
    "for tweet in X_tokens:\n",
    "    tweet_bow = dictionary.doc2bow(tweet)\n",
    "    if len(tweet_bow) > 1:\n",
    "        X_bow.append(tweet_bow)\n",
    "        keep_tweet.append(True)\n",
    "    else:\n",
    "        keep_tweet.append(False)\n",
    "\n",
    "df_data = df[keep_tweet]\n",
    "N = len(df_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_matrix = np.zeros([N, I])\n",
    "for i, doc_bow in enumerate(X_bow):\n",
    "    word_list = list()\n",
    "    for word in doc_bow:\n",
    "        X_matrix[i, word[0]] = word[1]\n",
    "X_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-291dcf03c236ebe6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# log sum exponential trick\n",
    "def compute_lset(ns):\n",
    "    return scipy.special.logsumexp(ns)\n",
    "\n",
    "# initialize parameters\n",
    "def initialize_parameters(N, K, alpha, gamma):\n",
    "    pi_vector = np.random.dirichlet(alpha, size=1).flatten()  # [K, ]\n",
    "    Z_matrix = np.random.multinomial(n=1, pvals=pi_vector, size=N)  # One hot encoding NxK\n",
    "    theta_matrix = np.random.dirichlet(gamma, size=K)  # [K, I]\n",
    "    return pi_vector, theta_matrix, Z_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4) Implement the log-likelihood of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2a3b9f88a223383c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def log_likelihood_X(X, Z, theta_matrix):\n",
    "    # FILL HERE\n",
    "    return log_lik"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5) Implement Algorithm 1, i.e. the posterior distributions obtained in point 1) and fill in the function *fit_no_collapsed_Gibbs*. Then, train the algorithm for 80 iterations with a burn in period τburn−in = 20 iterations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2841f752cb30c4f4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def pi_Z(Z, alpha):\n",
    "    # FILL HERE\n",
    "    return pi_sample\n",
    "\n",
    "def thetak_XZ(X, Z, k, gamma):\n",
    "    # FILL HERE\n",
    "    return thetak_sample\n",
    "\n",
    "def Z_pi_theta_xn(X, pi_vector, theta_matrix):\n",
    "    # FILL HERE\n",
    "    return  Z_probs, Z_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b6548bf4d7e1372c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Show the evolution of the log-likelihood per iteration.\n",
    "# Obtain the MAP estimate of the cluster assignments computed after τburn-in.\n",
    "\n",
    "def fit_no_collapsed_Gibbs(X, K, alpha, gamma, burn_in, n_iters):\n",
    "    # FILL HERE\n",
    "    return pi_vector, theta_matrix, Z_matrix, z_map, log_x_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-69ab9b60a9c30d79",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "np.random.seed(1234)\n",
    "\n",
    "alpha = 1*np.ones(K)\n",
    "gamma = np.ones(I)\n",
    "\n",
    "pi_vector, theta_matrix, Z_matrix, z_map, log_x_list = fit_no_collapsed_Gibbs(X_matrix, K, alpha, gamma, \n",
    "                                                                              burn_in=20, n_iters=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6) Using your implementation of Algorithm 1, and the implementations of Algorithm 2 and 3 provided in the jupyter notebook, explain the differences in convergence speed of the algorithms in terms of number of iterations and time. What is the reason behind those differences?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The implementations of Algorithm 2 and 3 are going to be provided after the tutorial."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
